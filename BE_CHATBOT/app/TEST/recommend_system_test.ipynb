{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "870f92cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Desktop\\DE_AN\\dean_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Admin\\Desktop\\DE_AN\\dean_env\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from rapidfuzz import fuzz\n",
    "from typing import List, Dict, Optional, Any, Tuple\n",
    "from langdetect import detect_langs\n",
    "import os\n",
    "from keybert import KeyBERT\n",
    "\n",
    "\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")\n",
    "QDRANT_URL = os.getenv(\"QDRANT_URL\")\n",
    "QDRANT_API_KEY =os.getenv(\"QDRANT_API_KEY\")\n",
    "QDRANT_COLLECTION_NAME = os.getenv(\"STORAGE\")\n",
    "\n",
    "qdrant_client = QdrantClient(\n",
    "    url=QDRANT_URL,\n",
    "    api_key=QDRANT_API_KEY\n",
    ")\n",
    "class RecommendationConfig:\n",
    "    MAX_RESULTS = 10\n",
    "    BRAND_MATCH_BOOST = 15\n",
    "    PRICE_RANGE_MATCH_BOOST = 15\n",
    "    TYPE_MATCH_BOOST = 5\n",
    "    HISTORY_MATCH_BOOST = 10\n",
    "    FUZZY_WEIGHT = 0.5\n",
    "    COSINE_WEIGHT = 0.5\n",
    "\n",
    "\n",
    "def ai_model():\n",
    "    return ChatOpenAI(\n",
    "        openai_api_key=OPENAI_API_KEY,       \n",
    "        model=\"gpt-4o-mini\",     \n",
    "        temperature=0,\n",
    "        max_tokens=3000\n",
    "    )\n",
    "\n",
    "def convert_to_string(value) -> str:\n",
    "    \"\"\"Convert any value to a string in a standardized way.\"\"\"\n",
    "    if isinstance(value, list):\n",
    "        return \" \".join(str(item) for item in value)\n",
    "    return str(value)\n",
    "\n",
    "def fuzzy_score(user_query: str, metadata: Dict) -> float:\n",
    "    \"\"\"Calculate enhanced fuzzy matching score using multiple algorithms.\"\"\"\n",
    "    if not user_query:\n",
    "        return 0.0\n",
    "    \n",
    "    user_query_lower = user_query.lower()\n",
    "    priority_fields = ['device_name','brand','category','discount_percent', 'sales_perks',\n",
    "                    'payment_perks','sales_price']\n",
    "    fuzzy_sim = 0\n",
    "    for field in priority_fields:\n",
    "        if field in metadata:\n",
    "            value_str = convert_to_string(metadata[field])\n",
    "            fuzzy_sim += fuzz.partial_ratio(user_query_lower, value_str.lower())\n",
    "    return fuzzy_sim\n",
    "\n",
    "def check_similarity(text1: str, texts: Optional[List[str]], vectorizer=None) -> float:\n",
    "    \"\"\"Calculate max cosine similarity between text1 and a list of strings. Optionally reuse a vectorizer.\"\"\"\n",
    "    if not text1 or not texts:\n",
    "        return 0.0\n",
    "    corpus = [text1] + texts\n",
    "    if vectorizer is None:\n",
    "        vectorizer = TfidfVectorizer().fit(corpus)\n",
    "    vectors = vectorizer.transform(corpus)\n",
    "    similarities = cosine_similarity(vectors[0], vectors[1:])[0]\n",
    "    return max(similarities) if similarities.size > 0 else 0.0\n",
    "\n",
    "kw_model = KeyBERT(model='paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "def keyword(user_query: str) -> str:\n",
    "    keywords_with_scores = kw_model.extract_keywords(\n",
    "    user_query,\n",
    "    keyphrase_ngram_range=(1, 2),\n",
    "    stop_words=None,\n",
    "    top_n=5,\n",
    "    use_mmr=True,\n",
    "    diversity=0.5,\n",
    "    seed_keywords=[\"phone\", \"laptop/pc\", \"earphone\", \"power bank\", \"mouse\", \"case\", \"keyboard\",\"apple\",\"xiaomi\",\"realme\",\"honor\",\"samsung\", \"oppo\", \"dell\", \"macbook\", \"msi\", \"asus\", \"hp\",\"lenovo\",\"acer\",'gigabyte',\"logitech\",\"marshall\"]\n",
    ")\n",
    "\n",
    "    keywords_str = \", \".join([kw for kw, _ in keywords_with_scores])\n",
    "\n",
    "    return keywords_str\n",
    "\n",
    "_cached_all_points = None\n",
    "def get_all_points(batch_size: int = 100):\n",
    "    \"\"\"Retrieve all points from Qdrant and cache the results for performance.\"\"\"\n",
    "    global _cached_all_points\n",
    "    if _cached_all_points is None:\n",
    "        _cached_all_points = qdrant_client.scroll(\n",
    "            collection_name=QDRANT_COLLECTION_NAME,\n",
    "            scroll_filter=None,\n",
    "            with_vectors=False,\n",
    "            with_payload=True,\n",
    "            limit=batch_size\n",
    "        )[0]\n",
    "    return _cached_all_points\n",
    "\n",
    "def recommend_system(\n",
    "    user_input: Optional[str] = None,\n",
    "    types: Optional[str] = None,\n",
    "    recent_history: Optional[List[Dict]] = None,\n",
    "    preference: Optional[Dict[str, Any]] = None,\n",
    "    custom_config: Optional[RecommendationConfig] = None,\n",
    ") -> Tuple[str, Optional[List[str]]]:\n",
    "    \"\"\"\n",
    "    Recommend products based on user input, types, preferences, and history.\n",
    "    User input is optional - system can recommend based on other parameters if not provided.\n",
    "    \"\"\"\n",
    "    config = custom_config or RecommendationConfig()\n",
    "    use_user_input = user_input is not None and user_input.strip() != \"\"\n",
    "    \n",
    "    main_query = \"\"\n",
    "    main_query_lower = \"\"\n",
    "    if use_user_input:\n",
    "        main_query = keyword(user_input)\n",
    "        main_query_lower = main_query.lower()\n",
    "    \n",
    "    language_input = user_input or types or \"\"\n",
    "    if not language_input and preference:\n",
    "        if \"brand\" in preference and isinstance(preference[\"brand\"], list) and preference[\"brand\"]:\n",
    "            language_input = preference[\"brand\"][0]\n",
    "    language = detect_langs(language_input)\n",
    "\n",
    "    all_points = get_all_points()\n",
    "    matched_docs = []\n",
    "    has_brands = has_types = has_history = has_price = False\n",
    "    brands = []\n",
    "    if preference and \"brand\" in preference and preference[\"brand\"]:\n",
    "        brands = [brand.lower() for brand in preference[\"brand\"]]\n",
    "        has_brands = len(brands) > 0\n",
    "    \n",
    "    user_types = []\n",
    "    if types:\n",
    "        user_types = types.lower().split()\n",
    "        has_types = len(user_types) > 0\n",
    "    \n",
    "    history_device_names = []\n",
    "    if recent_history:\n",
    "        history_device_names = [rh[\"device_name\"].lower() for rh in recent_history \n",
    "                            if isinstance(rh, dict) and \"device_name\" in rh]\n",
    "        has_history = len(history_device_names) > 0\n",
    "    \n",
    "    price_min = price_max = None\n",
    "    if preference and \"price_range\" in preference and preference[\"price_range\"]:\n",
    "        price_range = preference[\"price_range\"]\n",
    "        if isinstance(price_range, list):\n",
    "            has_price = True\n",
    "            if len(price_range) == 1:\n",
    "                price_max = price_range[0]\n",
    "            elif len(price_range) >= 2:\n",
    "                price_min, price_max = price_range[:2]\n",
    "\n",
    "    # Calculate scores for each document\n",
    "    for doc in all_points:\n",
    "        metadata = doc.payload.get(\"metadata\", {})\n",
    "        total_score = 0\n",
    "        \n",
    "        if use_user_input:\n",
    "            combined_fields = [\n",
    "                convert_to_string(metadata.get(\"device_name\", \"\")),\n",
    "                convert_to_string(metadata.get(\"brand\", \"\")),\n",
    "                convert_to_string(metadata.get(\"category\", \"\")),\n",
    "                convert_to_string(metadata.get(\"sales_perks\", \"\")),\n",
    "                convert_to_string(metadata.get(\"sales_price\", \"\")),\n",
    "                convert_to_string(metadata.get(\"discount_percent\", \"\")),\n",
    "                convert_to_string(metadata.get(\"payment_perks\", \"\"))\n",
    "            ]\n",
    "            cos_score = check_similarity(main_query_lower, combined_fields)\n",
    "            user_input_score = fuzzy_score(main_query_lower, metadata)\n",
    "            total_score += user_input_score * config.FUZZY_WEIGHT + cos_score * 100 * config.COSINE_WEIGHT\n",
    "        \n",
    "        if has_types:\n",
    "            doc_category = metadata.get(\"suitable_for\", \"\").lower()\n",
    "            if doc_category:\n",
    "                type_score = sum(fuzz.partial_ratio(t, doc_category) for t in user_types)\n",
    "                total_score += (type_score / len(user_types)) * config.TYPE_MATCH_BOOST / 100\n",
    "        \n",
    "        if has_brands:\n",
    "            doc_brand = metadata.get(\"brand\", \"\").lower()\n",
    "            if doc_brand:\n",
    "                brand_score = sum(fuzz.partial_ratio(b, doc_brand) for b in brands)\n",
    "                total_score += (brand_score / len(brands)) * config.BRAND_MATCH_BOOST / 100\n",
    "        \n",
    "        if has_price:\n",
    "            sale_price = metadata.get(\"sale_price\")\n",
    "            if isinstance(sale_price, (int, float)):\n",
    "                if price_min is not None and price_max is not None and price_min <= sale_price <= price_max:\n",
    "                    total_score += config.PRICE_RANGE_MATCH_BOOST\n",
    "                elif price_max is not None and sale_price <= price_max:\n",
    "                    total_score += config.PRICE_RANGE_MATCH_BOOST * 0.7\n",
    "                elif price_min is not None and sale_price >= price_min:\n",
    "                    total_score += config.PRICE_RANGE_MATCH_BOOST * 0.7\n",
    "        \n",
    "        if has_history:\n",
    "            doc_info = f\"{metadata.get('category', '').lower()} {metadata.get('brand', '').lower()} {metadata.get('device_name', '').lower()}\"\n",
    "            history_score = sum(fuzz.partial_ratio(h, doc_info) for h in history_device_names)\n",
    "            total_score += (history_score / len(history_device_names)) * config.HISTORY_MATCH_BOOST / 100\n",
    "        \n",
    "        matched_docs.append({\n",
    "            \"doc\": doc,\n",
    "            \"score\": total_score\n",
    "        })\n",
    "\n",
    "    matched_docs.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "    top_match_count = min(len(matched_docs), config.MAX_RESULTS)\n",
    "    top_matches = matched_docs[:top_match_count]\n",
    "    \n",
    "    top_device_names = []\n",
    "    for match in top_matches:\n",
    "        device_name = match[\"doc\"].payload.get(\"metadata\", {}).get(\"device_name\")\n",
    "        if device_name:\n",
    "            top_device_names.append(device_name)\n",
    "\n",
    "    if not top_matches:\n",
    "        return \"I couldn't find any products matching your criteria. Could you provide more specific details?\", []\n",
    "\n",
    "    search_context = \"\"\n",
    "\n",
    "    meta_fields = [\n",
    "        \"device_name\", \"cpu\", \"card\", \"screen\", \"storage\", \"image_link\",\n",
    "        \"sale_price\", \"discount_percent\", \"installment_price\",\n",
    "        \"colors\", \"sales_perks\", \"guarantee_program\", \"payment_perks\", \"source\"\n",
    "    ]\n",
    "\n",
    "    for idx, item in enumerate(top_matches, start=1):\n",
    "        meta = item[\"doc\"].payload.get(\"metadata\", {})\n",
    "        content = f\"Product {idx}:\\n\"\n",
    "        for field in meta_fields:\n",
    "            if field in meta:\n",
    "                if field in [\"sale_price\",\"installment_price\"]:\n",
    "                    value = meta[field]\n",
    "                    if isinstance(value, (int, float)):\n",
    "                        content += f\"- {field}: {value:,} VND\\n\"\n",
    "                    else:\n",
    "                        content += f\"- {field}: {value} VND\\n\"\n",
    "                elif field == \"discount_percent\":\n",
    "                    content += f\"- {field}: {meta[field]}%\\n\"\n",
    "                else:\n",
    "                    content += f\"- {field}: {meta[field]}\\n\"\n",
    "        search_context += content + \"\\n\\n\"\n",
    "    \n",
    "    source = top_matches[0][\"doc\"].payload.get(\"metadata\", {}).get(\"source\") if top_matches else \"\"\n",
    "    images = top_matches[0][\"doc\"].payload.get(\"metadata\", {}).get(\"image_link\") if top_matches else \"\"\n",
    "\n",
    "    llm = ai_model()\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"\n",
    "            You are a friendly and polite salesman for FPT Shop, specializing in phones and other tech devices.  \n",
    "            Your goal is to recommend products based on the `search_context` and the user's `user_query`.  \n",
    "\n",
    "            **IMPORTANT:**  \n",
    "            - Reply in the language that best matches the user's query (English or Vietnamese only; default to English if unclear).  \n",
    "            - Identify the best matching device from {retrieved_devices} by focusing on brand and price range, especially prioritizing the device that fits the user's preferences most closely.  \n",
    "            - Be brief and to the point. Focus on the best match.\n",
    "            - include all details from {search_context} for your main recommendation,(make sure to include sales_perks, paymen_perks) and add:  \n",
    "            - {source}  \n",
    "            - {images} \n",
    "            - Very briefly mention 1-2 alternative products if available.\n",
    "            - End with a simple question about which device they want more information about.\n",
    "        \"\"\"),\n",
    "        (\"human\", \"User query: {user_query}\\n\\nSearch results:\\n{search_context}\")\n",
    "    ])\n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\n",
    "        \"user_query\": user_input,\n",
    "        \"search_context\": search_context,\n",
    "        \"retrieved_devices\": top_device_names,\n",
    "        \"source\": source,\n",
    "        \"images\": images,\n",
    "        \"language\": language\n",
    "    })\n",
    "    \n",
    "    return response.content if hasattr(response, 'content') else response, top_device_names\n",
    "\n",
    "def get_device_details(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve detailed information about a specific device.\n",
    "    Uses a cache to avoid repeated lookups for the same device.\n",
    "    \"\"\"\n",
    "    \n",
    "    language = detect_langs(user_query)\n",
    "    \n",
    "    # Initialize variables\n",
    "    all_points = get_all_points()\n",
    "    matching_doc = None\n",
    "    source = None\n",
    "\n",
    "    try:\n",
    "        # Debug state contents\n",
    "        \n",
    "        # Get recommended devices from state\n",
    "        recommended_devices = ['iPhone 15 128GB', 'iPhone 16 128GB', 'iPhone 11 64GB', 'iPhone 13 128GB', 'iPhone 16e 128GB', 'iPhone 14 128GB', 'iPhone 15 Plus 128GB', 'iPhone 15 Pro 128GB', 'iPhone 14 Plus 128GB', 'iPhone 16 Plus 128GB']\n",
    "\n",
    "        \n",
    "        # Initialize matching_doc to None\n",
    "        matching_doc = None\n",
    "        \n",
    "        # Find the best match for the device\n",
    "        best_score = -1\n",
    "        best_match = None\n",
    "\n",
    "        if recommended_devices:\n",
    "            for rec_device in recommended_devices:\n",
    "                score = fuzz.ratio(user_query, rec_device.lower())\n",
    "                if score > best_score:\n",
    "                    for doc in all_points:\n",
    "                        metadata = doc.payload.get(\"metadata\", {})\n",
    "                        if metadata.get(\"device_name\", \"\") == rec_device:\n",
    "                            best_match = doc\n",
    "                            best_score = score\n",
    "                            print(f\"Top fuzzy match from recommendations: {rec_device} (score: {score})\")\n",
    "                            break\n",
    "        \n",
    "        if best_match:\n",
    "            matching_doc = best_match\n",
    "            source = matching_doc.payload.get(\"metadata\", {}).get(\"source\")\n",
    "            device_name = matching_doc.payload.get(\"metadata\", {}).get(\"device_name\", user_query)\n",
    "            print(f\"Using fuzzy match: {device_name} (score: {best_score})\")\n",
    "        \n",
    "        if not matching_doc:\n",
    "            return f\"No detailed information found for {user_query}. Please try another product.\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "    \n",
    "    detail = matching_doc.payload['page_content']\n",
    "\n",
    "    llm = ai_model()\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"\n",
    "                You are a product assistant for FPT Shop selling tech devices.\n",
    "                Provide concise information about the specific device.\n",
    "                Include links and image links if present.\n",
    "                Maintain the detected language.\n",
    "                End with a reference to {source} for more details.\n",
    "            \"\"\"),\n",
    "        (\"human\", \"device_name: {device_name}\\n\\nSearch results:\\n{detail}\\n\\nLanguage:\\n{language}\")\n",
    "    ])\n",
    "\n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\n",
    "        \"device_name\": device_name,\n",
    "        \"detail\": detail,\n",
    "        \"language\": language,\n",
    "        \"source\": source\n",
    "    })\n",
    "    \n",
    "    # Return the result\n",
    "    result = response.content if hasattr(response, 'content') else response\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e50675d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = recommend_system(\n",
    "    user_input=\"Tôi muốn xem các mẫu của Iphone 14\",\n",
    "    types='',\n",
    "    recent_history=[],\n",
    "    preference={\n",
    "        \"brand\": [\"Iphone, Xiaomi, Oppo, MSI\"],\n",
    "        \"price_range\": [10000000]\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e014ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"I see you're interested in the iPhone 14. Here are the details for the **iPhone 14 128GB**:\\n\\n- **Sale Price**: 12,790,000 VND\\n- **Discount**: 42%\\n- **Installment Price**: 1,067,000 VND\\n- **Colors**: Xanh dương, Trắng, Đen, Đỏ, Tím, Vàng\\n- **Sales Perks**: \\n  - Giảm ngay 9,200,000đ áp dụng đến 19/05\\n  - AirPods giảm đến 500,000đ khi mua kèm iPhone\\n  - Giảm thêm đến 2 triệu khi mua kèm SIM FPT FVIP150/F299 6-12 tháng\\n- **Payment Perks**: Giảm ngay 500,000đ cho đơn trên 15 triệu khi trả góp 100% qua thẻ VISA (áp dụng Sacombank và Muadee by HDBank)\\n- **Source**: [iPhone 14](https://fptshop.com.vn/dien-thoai/iphone-14)\\n- ![iPhone 14](https://cdn2.fptshop.com.vn/unsafe/iphone_14_48a46d1684.png)\\n\\nIf you're also considering alternatives, you might look at the **iPhone 15 128GB** or **iPhone 16 128GB**.\\n\\nWhich device would you like more information about?\",\n",
       " ['iPhone 15 Pro 128GB',\n",
       "  'iPhone 16 Plus 128GB',\n",
       "  'iPhone 15 Pro Max 256GB',\n",
       "  'Samsung Galaxy S25 5G 12GB 256GB',\n",
       "  'Samsung Galaxy S25 Plus 5G 12GB 256GB',\n",
       "  'Samsung Galaxy Z Fold6 5G 256GB',\n",
       "  'iPhone 14 128GB',\n",
       "  'Bộ bàn phím chuột không dây Icore ICKM800',\n",
       "  'iPhone 15 128GB',\n",
       "  'iPhone 16 128GB'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8952e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dean_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
